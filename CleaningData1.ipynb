{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the os package and list the solutions/downloaded directory to see which files we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USDCHF.json',\n",
       " 'USDCAD.json',\n",
       " 'GOOG.csv',\n",
       " 'NZDUSD.json',\n",
       " 'SHLD.csv',\n",
       " 'EURUSD.json',\n",
       " 'AMZN.csv',\n",
       " 'USDJPY.json',\n",
       " 'TSLA.csv',\n",
       " 'GBPUSD.json',\n",
       " 'AAPL.csv',\n",
       " 'AUDUSD.json']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('solutions/downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import the json and pandas libraries, and try to load one of the Forex files into a dataframe, inspecting the head() of the frame.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Close    DateTime    High     Low    Open\n",
      "0  1.2339  1523836800   1.234  1.2331  1.2332\n",
      "1  1.2336  1523840400  1.2343  1.2334  1.2340\n",
      "2   1.234  1523844000  1.2342  1.2334  1.2336\n",
      "3  1.2338  1523847600  1.2341  1.2338  1.2340\n",
      "4  1.2331  1523851200  1.2338  1.2331  1.2338\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open( 'solutions/downloaded/EURUSD.json','r') as handle:\n",
    "    eurusd_json = json.load( handle )\n",
    "\n",
    "eurusd_df = pd.DataFrame( eurusd_json )\n",
    "print( eurusd_df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty reasonable, so now we can use dtypes to print the python 'type' associated with each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close        object\n",
      "DateTime      int64\n",
      "High         object\n",
      "Low          object\n",
      "Open        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print( eurusd_df.dtypes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh. Our Open prices are float64s which looks good - but why are our other columns High, Low and Close all 'objects'?\n",
    "We can use pandas .astype() method on a series to convert it to float64s. We have to import numpy first as that's where float64 is defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not convert string to float: 'profit'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "try:\n",
    "    eurusd_df['High'] = eurusd_df['High'].astype(np.float64)\n",
    "except ValueError as e:\n",
    "    print( e )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! So somewhere in our 'High' column we have the word 'profit' as a string, which has caused pandas to coerce the entire column as strings. So what do we do about this?\n",
    "First, let's create a pandas Series, called 'high' which will be our 'High' column, but converted to numbers. If we use errors='coerce' it will fill bad values with NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = pd.to_numeric( eurusd_df.High, errors = 'coerce' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create a boolean map to find the NaN values with isna(), and then apply that index to the dataframe as a filter to find bad values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Close    DateTime    High     Low    Open\n",
      "247  1.2119  1525071600  profit  1.2109  1.2137\n"
     ]
    }
   ],
   "source": [
    "high_bad_index = high.isna()\n",
    "print( eurusd_df[high_bad_index] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it's just one row. This isn't so bad. So that column we created earlier, 'high', we know that is all proper numbers now, except one NaN, so let's replace the 'High' series in our dataframe with that converted series and then check dtypes again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close        object\n",
      "DateTime      int64\n",
      "High        float64\n",
      "Low          object\n",
      "Open        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "eurusd_df['High'] = high\n",
    "print(eurusd_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what about writing a general function to do this for us, whereby we pass it a dataframe and a column name we want forced numeric? Let's combine the steps we had above to do that for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Close    DateTime    High   Low    Open\n",
      "120  1.2271  1524441600  1.2279  &&&&  1.2274\n",
      "Close        object\n",
      "DateTime      int64\n",
      "High        float64\n",
      "Low         float64\n",
      "Open        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def make_numeric( df, col_name ):\n",
    "    ''' takes a dataframe and a column name and makes the column numeric, setting bad values to NaN '''\n",
    "    series_as_numbers = pd.to_numeric( df[ col_name ], errors='coerce' )\n",
    "    bad_index = series_as_numbers.isna()\n",
    "    print( df[ bad_index ] )\n",
    "    df[ col_name ] = series_as_numbers\n",
    "    return df\n",
    "\n",
    "eurusd_df = make_numeric( eurusd_df, 'Low' )\n",
    "print( eurusd_df.dtypes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So! There was one low price set to &&&&, not too bad, let's pass in the final price column, 'Close':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Close    DateTime    High     Low    Open\n",
      "40  None  1523980800  1.2357  1.2338  1.2345\n",
      "Close       float64\n",
      "DateTime      int64\n",
      "High        float64\n",
      "Low         float64\n",
      "Open        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "eurusd_df = make_numeric( eurusd_df, 'Close' )\n",
    "print( eurusd_df.dtypes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all our numbers are correctly typed as numbers, the real power of dataframes can be exploited. First let's fix up this DateTime, it's currenty a large integer specifying the number of seconds since the unix epoch (Midnight January 1st 1970). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Close    DateTime    High     Low    Open\n",
      "0  1.2339  1523836800  1.2340  1.2331  1.2332\n",
      "1  1.2336  1523840400  1.2343  1.2334  1.2340\n",
      "2  1.2340  1523844000  1.2342  1.2334  1.2336\n",
      "3  1.2338  1523847600  1.2341  1.2338  1.2340\n",
      "4  1.2331  1523851200  1.2338  1.2331  1.2338\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "print(eurusd_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a list comprehension to create a new index with the values of the DateTime column passed to datetime.fromtimestamp():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Close    DateTime    High     Low    Open\n",
      "2018-04-16 00:00:00+00:00  1.2339  1523836800  1.2340  1.2331  1.2332\n",
      "2018-04-16 01:00:00+00:00  1.2336  1523840400  1.2343  1.2334  1.2340\n",
      "2018-04-16 02:00:00+00:00  1.2340  1523844000  1.2342  1.2334  1.2336\n",
      "2018-04-16 03:00:00+00:00  1.2338  1523847600  1.2341  1.2338  1.2340\n",
      "2018-04-16 04:00:00+00:00  1.2331  1523851200  1.2338  1.2331  1.2338\n"
     ]
    }
   ],
   "source": [
    "eurusd_df.index = [ datetime.fromtimestamp( x, timezone.utc ) for x in eurusd_df['DateTime'] ]\n",
    "print( eurusd_df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful! We have a dataframe of all floating point pricings with an index properly cast as datetime objects. Now armed with this cleaner data we can go ahead and see if we can create a plot. Pandas is tightly integrated with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = plt.gca() # gca means get current axis\n",
    "\n",
    "eurusd_df.plot(kind='line',x='DateTime', y='High', color='green', ax=ax)\n",
    "eurusd_df.plot(kind='line',x='DateTime', y='Low', color='red', ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
